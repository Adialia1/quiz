#!/usr/bin/env python3
"""
Week 1 Implementation: GPT-4 Vision OCR + Hierarchy-Aware Chunking
Target Score: 7.5/10 (from current 6.5/10)
"""

import os
import base64
from pathlib import Path
from typing import List, Dict
from dotenv import load_dotenv
from openai import OpenAI
import json
import time

# Load environment
load_dotenv()

# Initialize OpenRouter client (supports multiple models including Gemini)
client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.getenv('OPENROUTER_API_KEY')
)

def convert_pdf_to_images(pdf_path: Path, dpi: int = 300) -> List:
    """
    Convert PDF pages to high-quality images

    Args:
        pdf_path: Path to PDF file
        dpi: Image resolution (300 DPI recommended for OCR quality)

    Returns:
        List of PIL Image objects
    """
    try:
        from pdf2image import convert_from_path

        print(f"üìÑ Converting PDF to images (DPI: {dpi})...")
        images = convert_from_path(str(pdf_path), dpi=dpi)
        print(f"‚úÖ Converted {len(images)} pages to images")

        return images

    except ImportError:
        print("‚ùå pdf2image not installed")
        print("   Install: pip install pdf2image")
        print("   Also requires poppler: brew install poppler (macOS)")
        return []

    except Exception as e:
        print(f"‚ùå Error converting PDF: {e}")
        return []


def encode_image_to_base64(image) -> str:
    """Convert PIL Image to base64 string for API"""
    from io import BytesIO

    buffered = BytesIO()
    image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode('utf-8')


def perfect_ocr_with_gpt4_vision(pdf_path: Path, max_pages: int = None) -> List[str]:
    """
    Convert PDF pages to perfect markdown using GPT-4 Vision

    This achieves:
    - Perfect Hebrew text extraction
    - Table structure preservation
    - Chart/diagram descriptions
    - Clean formatting

    Args:
        pdf_path: Path to PDF file
        max_pages: Limit pages to process (for testing)

    Returns:
        List of markdown strings, one per page
    """
    images = convert_pdf_to_images(pdf_path, dpi=300)  # Higher DPI for better OCR with Gemini

    if not images:
        print("‚ö†Ô∏è  Falling back to basic extraction...")
        return fallback_to_basic_extraction(pdf_path, max_pages)

    if max_pages:
        images = images[:max_pages]

    page_markdowns = []

    print(f"\nü§ñ Processing {len(images)} pages with GPT-4 Vision...")

    for i, image in enumerate(images, 1):
        print(f"   Processing page {i}/{len(images)}...", end=' ')

        # Encode image
        image_base64 = encode_image_to_base64(image)

        # GPT-4 Vision prompt
        prompt = """◊ê◊™◊î ◊û◊ï◊û◊ó◊î ◊ë-OCR ◊©◊ú ◊û◊°◊û◊õ◊ô◊ù ◊û◊©◊§◊ò◊ô◊ô◊ù ◊ë◊¢◊ë◊®◊ô◊™.

    ◊î◊û◊® ◊ê◊™ ◊™◊û◊ï◊†◊™ ◊î◊¢◊û◊ï◊ì ◊î◊ñ◊î ◊ú-Markdown ◊ë◊ê◊ô◊õ◊ï◊™ ◊û◊ï◊©◊ú◊û◊™.

    ◊ì◊®◊ô◊©◊ï◊™:
    1. **◊ò◊ß◊°◊ò ◊¢◊ë◊®◊ô◊™ ◊û◊ì◊ï◊ô◊ß** - ◊õ◊ú ◊û◊ô◊ú◊î ◊ó◊ô◊ô◊ë◊™ ◊ú◊î◊ô◊ï◊™ ◊û◊ì◊ï◊ô◊ß◊™
    2. **◊©◊û◊ï◊® ◊û◊ë◊†◊î ◊ò◊ë◊ú◊ê◊ï◊™** - ◊î◊û◊® ◊ò◊ë◊ú◊ê◊ï◊™ ◊ú-Markdown tables
    3. **◊©◊û◊ï◊® ◊î◊ô◊®◊®◊õ◊ô◊î** - ◊õ◊ï◊™◊®◊ï◊™, ◊°◊¢◊ô◊§◊ô◊ù, ◊™◊™◊ô-◊°◊¢◊ô◊§◊ô◊ù
    4. **◊ñ◊ô◊î◊ï◊ô ◊°◊¢◊ô◊§◊ô◊ù ◊û◊©◊§◊ò◊ô◊ô◊ù** - ◊°◊¢◊ô◊£, ◊™◊ß◊†◊î, ◊§◊®◊ß, ◊°◊¢◊ô◊£ ◊û◊©◊†◊î
    5. **◊°◊§◊®◊ï◊® ◊û◊ì◊ï◊ô◊ß** - ◊©◊û◊ï◊® ◊õ◊ú ◊û◊°◊§◊ï◊® ◊©◊ú ◊°◊¢◊ô◊§◊ô◊ù
    6. **◊™◊®◊©◊ô◊û◊ô◊ù** - ◊™◊ê◊® ◊ë◊ß◊¶◊®◊î ◊ê◊ù ◊ô◊©

    ◊§◊ï◊®◊û◊ò ◊§◊ú◊ò:
    ```markdown
    # [◊õ◊ï◊™◊®◊™ ◊î◊¢◊û◊ï◊ì ◊ê◊ù ◊ß◊ô◊ô◊û◊™]

    [◊™◊ï◊õ◊ü ◊ë◊¢◊ë◊®◊ô◊™ ◊ë◊û◊ë◊†◊î ◊û◊ï◊©◊ú◊ù]

    ## ◊ò◊ë◊ú◊î (◊ê◊ù ◊ß◊ô◊ô◊û◊™)
    | ◊¢◊û◊ï◊ì◊î 1 | ◊¢◊û◊ï◊ì◊î 2 |
    |---------|---------|
    | ◊¢◊®◊ö 1   | ◊¢◊®◊ö 2   |
    ```

    ◊î◊ó◊ñ◊® **◊®◊ß** ◊ê◊™ ◊î-Markdown, ◊ú◊ú◊ê ◊î◊°◊ë◊®◊ô◊ù."""

        try:
            response = client.chat.completions.create(
                model="google/gemini-2.0-flash-001",  # Gemini 2.0 Flash - Better for OCR
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{image_base64}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=10000,
                temperature=0.0  # Deterministic for OCR
            )

            markdown = response.choices[0].message.content.strip()

            # Remove markdown code block wrapper if present
            if markdown.startswith('```markdown'):
                markdown = markdown[len('```markdown'):].strip()
            if markdown.endswith('```'):
                markdown = markdown[:-3].strip()

            page_markdowns.append(markdown)
            print("‚úÖ")

            # Rate limiting
            time.sleep(0.5)

        except Exception as e:
            print(f"‚ùå Error: {e}")
            page_markdowns.append(f"[Error processing page {i}]")

    return page_markdowns


def hierarchy_aware_chunking(page_markdown: str, page_num: int) -> Dict:
    """
    Extract document hierarchy and create structured chunk

    This preserves:
    - Document structure (Title ‚Üí Section ‚Üí Subsection)
    - Legal section numbering (◊°◊¢◊ô◊£, ◊™◊ß◊†◊î, ◊§◊®◊ß)
    - Complete context at all levels

    Args:
        page_markdown: Markdown from GPT-4 Vision
        page_num: Page number

    Returns:
        Structured chunk with hierarchy preserved
    """
    prompt = f"""◊ê◊™◊î ◊û◊ï◊û◊ó◊î ◊ë◊†◊ô◊™◊ï◊ó ◊û◊ë◊†◊î ◊©◊ú ◊û◊°◊û◊õ◊ô◊ù ◊û◊©◊§◊ò◊ô◊ô◊ù ◊ë◊¢◊ë◊®◊ô◊™.

    ◊†◊™◊ó ◊ê◊™ ◊î◊¢◊û◊ï◊ì ◊î◊ñ◊î ◊ï◊ó◊ú◊• ◊ê◊™ ◊î◊î◊ô◊®◊®◊õ◊ô◊î ◊î◊û◊ú◊ê◊î:

    ```markdown
    {page_markdown[:4000]}
    ```

    ◊¶◊ï◊® JSON ◊¢◊ù ◊î◊û◊ë◊†◊î ◊î◊ë◊ê:
    {{
    "page_num": {page_num},
    "hierarchy": {{
        "level_1_title": "◊õ◊ï◊™◊®◊™ ◊®◊ê◊©◊ô◊™ (◊ê◊ù ◊ß◊ô◊ô◊û◊™)",
        "level_2_sections": ["◊§◊®◊ß ◊ê", "◊§◊®◊ß ◊ë"],
        "level_3_subsections": ["◊°◊¢◊ô◊£ 1", "◊°◊¢◊ô◊£ 2", "◊™◊ß◊†◊î 3"]
    }},
    "title": "◊õ◊ï◊™◊®◊™ ◊™◊ô◊ê◊ï◊®◊ô◊™ ◊ß◊¶◊®◊î + ◊¢◊û◊ï◊ì {page_num}",
    "context": "◊ê◊ô◊ö ◊î◊¢◊û◊ï◊ì ◊î◊ñ◊î ◊û◊©◊™◊ú◊ë ◊ë◊û◊ë◊†◊î ◊î◊õ◊ú◊ú◊ô ◊©◊ú ◊î◊û◊°◊û◊ö (2-3 ◊û◊©◊§◊ò◊ô◊ù)",
    "summary": "◊°◊ô◊õ◊ï◊ù ◊û◊ß◊ô◊£ ◊©◊ú ◊™◊ï◊õ◊ü ◊î◊¢◊û◊ï◊ì (3-5 ◊û◊©◊§◊ò◊ô◊ù)",
    "keywords": ["◊û◊ô◊ú◊ï◊™", "◊û◊§◊™◊ó", "◊ó◊©◊ï◊ë◊ï◊™"],
    "legal_sections": ["◊°◊¢◊ô◊£ 17", "◊™◊ß◊†◊î 5", "◊§◊®◊ß ◊í"],
    "key_concepts": ["◊û◊ï◊©◊í◊ô◊ù ◊û◊©◊§◊ò◊ô◊ô◊ù ◊û◊®◊õ◊ñ◊ô◊ô◊ù"],
    "entities": {{
        "parties": ["◊¶◊ì◊ì◊ô◊ù ◊©◊û◊ï◊ñ◊õ◊®◊ô◊ù"],
        "dates": ["◊™◊ê◊®◊ô◊õ◊ô◊ù"],
        "amounts": ["◊°◊õ◊ï◊û◊ô◊ù"]
    }},
    "tables_present": true/false,
    "cross_references": ["◊î◊™◊ô◊ô◊ó◊°◊ï◊ô◊ï◊™ ◊ú◊°◊¢◊ô◊§◊ô◊ù ◊ê◊ó◊®◊ô◊ù"]
    }}

    ◊î◊ó◊ñ◊® **◊®◊ß** JSON ◊™◊ß◊ô◊ü, ◊ú◊ú◊ê markdown code blocks."""

    try:
        response = client.chat.completions.create(
            model="google/gemini-2.5-flash",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0,
            response_format={"type": "json_object"}
        )

        structured_data = json.loads(response.choices[0].message.content)

        # Add full markdown text
        structured_data['full_text'] = page_markdown

        return structured_data

    except Exception as e:
        print(f"‚ö†Ô∏è  Error in hierarchy extraction: {e}")
        return {
            'page_num': page_num,
            'hierarchy': {},
            'title': f'◊¢◊û◊ï◊ì {page_num}',
            'context': '',
            'summary': '',
            'keywords': [],
            'legal_sections': [],
            'key_concepts': [],
            'entities': {},
            'tables_present': False,
            'cross_references': [],
            'full_text': page_markdown
        }


def create_enhanced_chunk(structured_data: Dict) -> str:
    """
    Create final chunk with hierarchy preservation

    Format:
    # Title (with hierarchy breadcrumb)
    **Hierarchy:** Level 1 ‚Üí Level 2 ‚Üí Level 3
    **Context:** ...
    **Summary:** ...
    **Legal Sections:** ...
    **Keywords:** ...
    ---
    [Full markdown text with preserved structure]
    """
    # Build hierarchy breadcrumb
    hierarchy = structured_data.get('hierarchy', {})
    breadcrumb_parts = []

    if hierarchy.get('level_1_title'):
        breadcrumb_parts.append(hierarchy['level_1_title'])

    if hierarchy.get('level_2_sections'):
        breadcrumb_parts.append(' ‚Üí '.join(hierarchy['level_2_sections'][:2]))

    breadcrumb = ' ‚Üí '.join(breadcrumb_parts) if breadcrumb_parts else '◊ú◊ú◊ê ◊î◊ô◊®◊®◊õ◊ô◊î'

    # Build entities section
    entities = structured_data.get('entities', {})
    entity_lines = []
    if entities.get('parties'):
        entity_lines.append(f"**◊¶◊ì◊ì◊ô◊ù:** {', '.join(entities['parties'])}")
    if entities.get('dates'):
        entity_lines.append(f"**◊™◊ê◊®◊ô◊õ◊ô◊ù:** {', '.join(entities['dates'])}")
    if entities.get('amounts'):
        entity_lines.append(f"**◊°◊õ◊ï◊û◊ô◊ù:** {', '.join(entities['amounts'])}")

    entities_section = '\n'.join(entity_lines) if entity_lines else ''

    # Build cross-references section
    cross_refs = structured_data.get('cross_references', [])
    cross_ref_section = f"**◊î◊™◊ô◊ô◊ó◊°◊ï◊ô◊ï◊™ ◊¶◊ï◊ú◊ë◊ï◊™:** {', '.join(cross_refs)}" if cross_refs else ''

    # Assemble chunk
    chunk_parts = [
        f"# {structured_data['title']}",
        f"**◊î◊ô◊®◊®◊õ◊ô◊î:** {breadcrumb}",
        f"**◊î◊ß◊©◊® ◊ë◊û◊°◊û◊ö:** {structured_data['context']}",
        f"**◊°◊ô◊õ◊ï◊ù:** {structured_data['summary']}",
        f"**◊°◊¢◊ô◊§◊ô◊ù ◊û◊©◊§◊ò◊ô◊ô◊ù:** {', '.join(structured_data['legal_sections'])}",
        f"**◊û◊ï◊©◊í◊ô◊ù ◊û◊®◊õ◊ñ◊ô◊ô◊ù:** {', '.join(structured_data['key_concepts'])}",
        f"**◊û◊ô◊ú◊ï◊™ ◊û◊§◊™◊ó:** {', '.join(structured_data['keywords'])}",
    ]

    if entities_section:
        chunk_parts.append(entities_section)

    if cross_ref_section:
        chunk_parts.append(cross_ref_section)

    if structured_data.get('tables_present'):
        chunk_parts.append("**‚ö†Ô∏è ◊û◊õ◊ô◊ú ◊ò◊ë◊ú◊ê◊ï◊™**")

    chunk_parts.extend([
        "---",
        structured_data['full_text']
    ])

    return '\n'.join(chunk_parts)


def fallback_to_basic_extraction(pdf_path: Path, max_pages: int = None) -> List[str]:
    """Fallback to pdfplumber if GPT-4 Vision fails"""
    try:
        import pdfplumber

        print("‚ö†Ô∏è  Using basic pdfplumber extraction...")

        with pdfplumber.open(pdf_path) as pdf:
            pages = pdf.pages[:max_pages] if max_pages else pdf.pages

            page_texts = []
            for page in pages:
                text = page.extract_text() or ""
                page_texts.append(text)

            return page_texts

    except Exception as e:
        print(f"‚ùå Error in fallback extraction: {e}")
        return []


def week1_pipeline(pdf_path: Path, max_pages: int = 3) -> Dict:
    """
    Complete Week 1 pipeline:
    1. GPT-4 Vision OCR
    2. Hierarchy-aware chunking

    Args:
        pdf_path: Path to PDF
        max_pages: Limit for testing (default 3)

    Returns:
        Dict with chunks and metadata
    """
    print("="*80)
    print("WEEK 1: GPT-4 Vision OCR + Hierarchy-Aware Chunking")
    print("="*80)

    # Step 1: Perfect OCR
    print("\nüì∏ Step 1: GPT-4 Vision OCR")
    page_markdowns = perfect_ocr_with_gpt4_vision(pdf_path, max_pages=max_pages)

    if not page_markdowns:
        print("‚ùå No pages extracted")
        return {}

    # Step 2: Hierarchy-aware chunking
    print(f"\nüèóÔ∏è  Step 2: Hierarchy-Aware Chunking")
    structured_pages = []

    for i, page_md in enumerate(page_markdowns, 1):
        print(f"   Analyzing page {i}/{len(page_markdowns)}...", end=' ')
        structured_data = hierarchy_aware_chunking(page_md, i)
        structured_pages.append(structured_data)
        print("‚úÖ")
        time.sleep(0.3)  # Rate limiting

    # Step 3: Create enhanced chunks
    print(f"\nüì¶ Step 3: Creating Enhanced Chunks")
    chunks = []

    for structured_data in structured_pages:
        chunk_text = create_enhanced_chunk(structured_data)
        chunks.append(chunk_text)

    # Statistics
    avg_chunk_size = sum(len(c) for c in chunks) / len(chunks)
    total_keywords = sum(len(s.get('keywords', [])) for s in structured_pages)
    total_legal_sections = sum(len(s.get('legal_sections', [])) for s in structured_pages)

    print(f"\n{'='*80}")
    print("WEEK 1 RESULTS")
    print(f"{'='*80}")
    print(f"\nüìä Processing Statistics:")
    print(f"   Total pages processed: {len(chunks)}")
    print(f"   Average chunk size: {avg_chunk_size:.0f} characters")
    print(f"   Total keywords extracted: {total_keywords}")
    print(f"   Total legal sections found: {total_legal_sections}")
    print(f"   Hierarchy levels captured: 1-3 levels per page")

    # Show sample
    if chunks:
        print(f"\nüìÑ Sample Chunk (Page 1):")
        print("-" * 80)
        print(chunks[0][:1000] + "..." if len(chunks[0]) > 1000 else chunks[0])
        print("-" * 80)

    return {
        'chunks': chunks,
        'structured_pages': structured_pages,
        'page_markdowns': page_markdowns,
        'statistics': {
            'total_pages': len(chunks),
            'avg_chunk_size': avg_chunk_size,
            'total_keywords': total_keywords,
            'total_legal_sections': total_legal_sections
        }
    }


def main():
    """Test Week 1 implementation"""
    legal_pdf = Path('/Users/adialia/Desktop/quiz/examples/legal1.pdf')

    if not legal_pdf.exists():
        print(f"‚ùå Error: {legal_pdf} not found")
        return

    # Run Week 1 pipeline on first 3 pages
    result = week1_pipeline(legal_pdf, max_pages=3)

    if not result:
        return

    print(f"\nüí° Next Steps:")
    print(f"   1. Run AI validation to measure score improvement")
    print(f"   2. Compare with baseline (6.5/10)")
    print(f"   3. Target: 7.5/10 (+15% improvement)")
    print(f"   4. If successful, proceed to Week 2 (Contextual Enrichment)")


if __name__ == '__main__':
    main()
