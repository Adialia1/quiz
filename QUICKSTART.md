# ğŸš€ Quick Start Guide

## âœ… Phase 1 Complete: RAG Infrastructure

You now have a **production-ready dual RAG system** with:

1. âœ… **Supabase database** - Schema setup complete
2. âœ… **Legal Documents RAG** - OCR + Semantic chunking + Vector search
3. âœ… **Exam Questions RAG** - Question storage + Similarity search
4. âœ… **Ingestion pipelines** - Ready to process PDFs and questions

---

## ğŸ¯ Next Immediate Steps

### Step 1: Install Dependencies (5 minutes)

```bash
cd /Users/adialia/Desktop/quiz

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install all packages
pip install -r requirements.txt
```

### Step 2: Enable pgvector in Supabase (2 minutes)

1. Go to https://supabase.com/dashboard
2. Select your project: `omgykoftsrtyipmykamk`
3. Click **Database** â†’ **Extensions**
4. Search for `vector`
5. Click **Enable** next to "vector"

### Step 3: Setup Database Schema (2 minutes)

**Option A: Supabase SQL Editor (Recommended)**

1. Go to https://supabase.com/dashboard
2. Select your project
3. Click **SQL Editor** in left menu
4. Click **New Query**
5. Open `scripts/schema.sql` and copy all contents
6. Paste into SQL Editor
7. Click **Run** (or press Cmd+Enter)

You should see: `Success. No rows returned`

**Option B: Verify Setup via Python**

```bash
python scripts/setup_supabase_simple.py
```

**Expected output:**
```
âœ… Configuration valid
âœ… Connected to Supabase

Checking tables...
âœ… legal_doc_chunks
âœ… exam_questions
âœ… users
âœ… user_performance
âœ… chat_messages
âœ… study_sessions
âœ… topic_mastery

ğŸ‰ All tables exist! Setup is complete.
```

### Step 4: Ingest Legal Documents

You have **16 PDFs** in `legal_documents/` ready to ingest!

**Option A: Test with one document first** (Recommended)

```bash
# Test with 5 pages from one PDF
python scripts/ingest_legal_docs.py legal_documents/1193856b-495b-4ce3-b796-33e7548e739c.pdf --max-pages 5
```

**Option B: Ingest ALL documents** (Takes ~30 min for 16 PDFs)

```bash
# Ingest all PDFs in legal_documents folder
python scripts/ingest_all_legal_docs.py

# Or skip already processed documents
python scripts/ingest_all_legal_docs.py --skip-existing
```

**Option C: Bash script** (same as Option B)

```bash
chmod +x scripts/ingest_all_legal_docs.sh
./scripts/ingest_all_legal_docs.sh
```

**What happens:**
- OCR extracts text from PDF (~10-20 sec/page)
- Creates semantic chunks
- Generates embeddings
- Stores in Supabase

**Expected output:**
```
ğŸ”„ Converting PDF to images (300 DPI)...
âœ… Processing 5 pages with Gemini 2.0 Flash...
   Page 1/5... âœ…
   Page 2/5... âœ…
   ...
âœ… OCR Complete: 5 pages, 12,450 chars

ğŸ“Š Chunking document...
âœ… Created 23 chunks

ğŸ”„ Generating embeddings...
âœ… Embeddings generated

[4/4] Inserting into Supabase...
âœ… Successfully inserted 23 chunks
```

### Step 5: Test Legal RAG

```bash
python rag/legal_rag.py
```

This will:
- Connect to your vector database
- Run test queries in Hebrew
- Show you the search results

### Step 6: Prepare Exam Questions

Create a JSON file: `questions.json`

```json
[
  {
    "question": "××” ×”×”×’×“×¨×” ×©×œ '××™×© ×¤× ×™×' ×œ×¤×™ ×—×•×§ × ×™×™×¨×•×ª ×¢×¨×š?",
    "options": {
      "A": "×›×œ ×¢×•×‘×“ ×‘×—×‘×¨×” ×¦×™×‘×•×¨×™×ª",
      "B": "××™ ×©××—×–×™×§ ×‘××™×“×¢ ×¤× ×™×",
      "C": "×‘×¢×œ ×× ×™×•×ª ×‘×¢×œ ×©×œ×™×˜×”",
      "D": "×—×‘×¨ ×“×™×¨×§×˜×•×¨×™×•×Ÿ ×‘×œ×‘×“",
      "E": "×›×œ ×”× \"×œ"
    },
    "correct_answer": "B",
    "explanation": "××™×© ×¤× ×™× ××•×’×“×¨ ×›××™ ×©××—×–×™×§ ×‘××™×“×¢ ×¤× ×™× ×‘×©×œ ×ª×¤×§×™×“×•, ××¢××“×• ××• ×§×©×¨×™×• ×¢× ×”×ª××’×™×“.",
    "topic": "××™×“×¢ ×¤× ×™×",
    "difficulty": "medium",
    "legal_reference": "×—×•×§ × ×™×™×¨×•×ª ×¢×¨×š, ×”×ª×©×›\"×—-1968, ×¡×¢×™×£ 52(×)"
  },
  {
    "question": "××”×• ×”×¢×•× ×© ×¢×œ ×©×™××•×© ×‘××™×“×¢ ×¤× ×™×?",
    "options": {
      "A": "×§× ×¡ ×‘×œ×‘×“",
      "B": "×××¡×¨ ×¢×“ 5 ×©× ×™×",
      "C": "×××¡×¨ ×¢×“ 5 ×©× ×™× ××• ×§× ×¡ ×¤×™ 10 ××”×¨×•×•×—",
      "D": "×”×©×¢×™×” ××”××¡×—×¨",
      "E": "××–×”×¨×” ×‘×›×ª×‘"
    },
    "correct_answer": "C",
    "explanation": "×”×¢×•× ×© ×¢×œ ×©×™××•×© ×‘××™×“×¢ ×¤× ×™× ×›×•×œ×œ ×××¡×¨ ×©×œ ×¢×“ 5 ×©× ×™× ××• ×§× ×¡ ×©×œ ×¢×“ ×¤×™ 10 ××”×¨×•×•×— ×©× ×¦×‘×¨ ××• ×”×”×¤×¡×“ ×©× ×× ×¢.",
    "topic": "××™×“×¢ ×¤× ×™×",
    "difficulty": "hard",
    "legal_reference": "×—×•×§ × ×™×™×¨×•×ª ×¢×¨×š, ×”×ª×©×›\"×—-1968, ×¡×¢×™×£ 53"
  }
]
```

### Step 7: Ingest Exam Questions

```bash
python scripts/ingest_exam_questions.py questions.json
```

**Expected output:**
```
ğŸ“„ Loading questions from: questions.json
âœ… Loaded 2 questions

ğŸ”„ Processing 2 questions
âœ… Embeddings generated

ğŸ”„ Inserting into Supabase...
âœ… Successfully inserted 2 questions

ğŸ“Š EXAM QUESTIONS DATABASE STATS
Total Questions: 2

By Topic:
   ××™×“×¢ ×¤× ×™×................................    2
```

### Step 8: Test Exam RAG

```bash
python rag/exam_rag.py
```

---

## ğŸ‰ You're Ready!

You now have:
- âœ… Dual RAG system working
- âœ… Legal documents indexed and searchable
- âœ… Exam questions indexed
- âœ… Semantic search operational

---

## ğŸ“Š What You Can Do Now

### Search Legal Documents
```python
from rag.legal_rag import LegalRAG

rag = LegalRAG()
results = rag.search("××”× ×”×¢×•× ×©×™× ×¢×œ ××™×“×¢ ×¤× ×™×?", k=5)
```

### Find Similar Questions
```python
from rag.exam_rag import ExamRAG

rag = ExamRAG()
questions = rag.find_questions_on_concept("××™×“×¢ ×¤× ×™×", k=10)
```

### Generate Practice Exams
```python
exam = rag.get_balanced_exam(count=25)  # Balanced across all topics
```

---

## ğŸš€ Next Phase: LangChain Agents

Now that RAG infrastructure is ready, you can:

1. **Build LangChain Agents** (see PRD.MD for all 8 agents)
   - Legal Expert Agent (uses Legal RAG)
   - Question Analyzer Agent (uses Exam RAG)
   - Explanation Generator Agent (uses both)
   - etc.

2. **Create FastAPI Backend**
   - REST API endpoints
   - WebSocket for chat
   - User authentication

3. **AWS Parallel Processing**
   - Batch process 50+ documents at once
   - S3 + Lambda + Batch setup

---

## ğŸ’¡ Pro Tips

### Batch Ingestion
```bash
# Ingest all PDFs in a folder
python scripts/ingest_legal_docs.py legal_documents/*.pdf

# Skip already processed
python scripts/ingest_legal_docs.py legal_documents/ --skip-existing

# Check what's in database
python scripts/ingest_legal_docs.py --check-only
```

### View Database Stats
```bash
# Exam questions stats
python scripts/ingest_exam_questions.py --stats

# Legal docs count
python rag/vector_store.py
```

### Test Individual Components
```bash
# Test OCR only
python ingestion/ocr_utils.py legal1.pdf 5

# Test chunking only
python ingestion/semantic_chunking.py
```

---

## ğŸ› Common Issues

### "Module not found"
```bash
pip install -r requirements.txt
```

### "pgvector not enabled"
Enable it in Supabase dashboard â†’ Database â†’ Extensions â†’ vector

### "Rate limit exceeded"
Edit `config/settings.py`:
```python
OCR_RATE_LIMIT_DELAY = 1.0  # Increase delay
```

### "Out of memory"
Process fewer pages:
```bash
python scripts/ingest_legal_docs.py file.pdf --max-pages 10
```

---

## ğŸ“ Questions?

Check:
1. `README.md` - Full documentation
2. `PRD.MD` - Product requirements and agent specs
3. Each script has `--help` flag

---

**You've completed Phase 1! Ready to build the agents? ğŸš€**
